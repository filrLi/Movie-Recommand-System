{"cells":[{"cell_type":"markdown","metadata":{},"source":"# User-Based recommender system\nThis notebook is written by Zitong Li"},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":"import pandas as pd\nimport copy as cp"},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":"data = pd.read_csv('../Data/ratings.csv')\ndata = data[['userId', 'movieId','rating']]\nmovies = pd.read_csv('../Data/movies.csv')\nmovies = movies[['movieId', 'title']]"},{"cell_type":"markdown","metadata":{},"source":"### Train test split\nFor each user in all users, select fixed portion of movies he watched as train set and the rest as test set."},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":"def train_test_split(data, seed = 6, portion = 0.8):\n    train_set = {}\n    test_set = {}\n    for user, movies in data.groupby('userId'):\n        movies = movies.sample(frac=1, random_state=seed).reset_index(drop=True)\n        train = movies[:int(portion*len(movies))]\n        test = movies[int(portion*len(movies)):]\n        train_set[user] = train[['movieId', 'rating']]\n        test_set[user] = test[['movieId', 'rating']]\n    #print('Data preparation finished')\n    return train_set, test_set"},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":"def itemUserAndRating(train_set):\n    item_user = {}\n    rating = {}\n    for u, items in train_set.items():\n        rating[u] = {}\n        movies = items['movieId'].tolist()\n        ratings = items['rating'].tolist()\n        for inum in range(len(movies)):\n            i = movies[inum]\n            rating[u][i] = [ratings[inum], 0]\n            if i not in item_user.keys():\n                item_user[i] = set()\n            item_user[i].add(u)\n    return item_user, rating\n"},{"cell_type":"markdown","metadata":{},"source":["### User-base theory\n","1. Caculate the matrix of user similarity based on cosin similarity\n","2. For a specific combination of user and item, (u, i), in all the other users who watched movie i, choose the top K most similar users to the use u.\n","3. Predict the score for such combination based on those top K similar users."]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":"from operator import itemgetter\nimport numpy as np\n\ndef User_Similarity(train_set):\n    N = {}\n    C = {}\n    W = {}\n    for u, u_movie in train_set.items():\n        N[u] = u_movie.shape[0]\n        C[u] = {}\n        W[u] = {}\n        for v in train_set.keys():\n            C[u][v] = 0\n            W[u][v] = 0\n    # Build inverse table\n    item_user, rating = itemUserAndRating(train_set)\n    for i, users in item_user.items():\n        for u in users:\n            for v in users:\n                if v != u:\n                    urating = rating[u][i][0]\n                    vrating = rating[v][i][0]\n                    corating = 5 - abs(urating - vrating)\n                    C[u][v] += 1/np.log(1+len(users)*1.0) * corating\n    \n    # Calculate similarity matrix\n    for u, related_users in C.items():\n        for v, cuv in related_users.items():\n            W[u][v] = cuv/(N[u]*N[v])**0.5\n    print('user similarity finished')\n    return W\n"},{"cell_type":"markdown","metadata":{},"source":["Predict all the possible ratings"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":"def predict(train_set, K, user_sim):\n    # store the original ratings\n    item_user, orig_ratings = itemUserAndRating(train_set)\n\n    predict_ratings = cp.copy(orig_ratings)\n    for u, wu in user_sim.items():  # u is the user, wu is the user similarity list of u\n        # already_items is the movies already watched by u\n        already_items = train_set[u]['movieId'].tolist()\n        for item, vs in item_user.items():  # item is some movie, vs is the list of peopele who watched this movie\n            if item not in already_items:\n                # friendNum is the total amount of users we can use to predict for u with movie item\n                friendNum = min(K, len(vs))\n                wuv = [(v, wu[v]) for v in vs]\n                topv = sorted(wuv, key=itemgetter(1), reverse=True)[\n                    :friendNum]  # topv store the v id and wuv\n                sum_wuv = sum([_[1] for _ in topv])\n                if sum_wuv == 0:\n                    #nobody wathced this movie\n                    continue\n                topv_normal = [(_[0], _[1]/sum_wuv)\n                               for _ in topv]  # normalise the similarity\n                if item not in predict_ratings[u]:\n                    predict_ratings[u][item] = [0, 0]\n                for v in topv_normal:\n                    # the predict rating is the sum of product of related users's ratings and his similarity\n                    predict_ratings[u][item][0] += orig_ratings[v[0]][item][0] * v[1]\n                for v in topv:\n                    predict_ratings[u][item][1] += orig_ratings[v[0]][item][0] * v[1]\n        predict_ratings[u] = sorted(predict_ratings[u].items(), key = itemgetter(0))\n    print('prediction finished.')\n    return predict_ratings"},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":"def rmse(predict, real):\n    return np.sqrt(np.mean((predict-real)**2))"},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":"# get the performance score of the predictions\ndef get_score(predictions, test_set):\n    rmselist = []\n    p = cp.copy(predictions)\n    for user in test_set.keys():\n        p[user] = list(map(lambda x:(x[0], x[1][0]), p[user]))\n        prediction = pd.DataFrame(p[user], columns=['movieId', user])\n        test = test_set[user]\n        merge = pd.merge(prediction, test)\n        user_error = rmse(merge[user], merge['rating'])\n        #print(f\"For user {user}, test error = {user_error}\")\n        rmselist.append(user_error)\n    return np.mean(rmselist)"},{"cell_type":"markdown","metadata":{},"source":["Let's test the model and get the rmse score"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"user similarity finished\nprediction finished.\n0.9460420702603404\n"}],"source":"train_set, test_set = train_test_split(data)\nuser_similarity = User_Similarity(train_set)\npredictions = predict(train_set, 20, user_similarity)\nprint(get_score(predictions, test_set))\n"},{"cell_type":"markdown","metadata":{},"source":"Let's do the cross validation and get a more convinceble error and variance."},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":"def cross_validation(data, fold = 5, K = 20):\n    score_list = []\n    for seed in range(fold):\n        train_set, test_set = train_test_split(data, seed)\n        user_similarity = User_Similarity(train_set)\n        predictions = predict(train_set, K, user_similarity)\n        test_score = get_score(predictions, test_set)\n        print(f\"test:{seed}, rmse is {test_score}.\")\n        score_list.append(test_score)\n    return np.mean(score_list), np.var(score_list,ddof=1)"},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":"mean, variance = cross_validation(data)\nprint('____________________________________')\nprint(f\"Mean RMSE: {mean}, variance {variance}\")"},{"cell_type":"markdown","metadata":{},"source":["Let's see how will the score change if we modify the K values"]},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":"import matplotlib.pyplot as plt\n%matplotlib inline\n\ntrain_set, test_set = train_test_split(data)\nerror = []\nx = []\nuser_similarity = User_Similarity(train_set)\nfor K in range(1, 16, 2):\n    predictions = predict(train_set, K, user_similarity)\n    test_score = get_score(predictions, test_set)\n    print(f\"K:{K}, rmse is {test_score}.\")\n    error.append(test_score)\n    x.append(K)\nplt.plot(x, error)\nplt.xlabel('K')\nplt.ylabel('rmse error')\nplt.show()\n"},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":"movies = pd.read_csv('./ml-latest-small/movies.csv')\nmovies = movies[['movieId', 'title']]\nmovies = movies.set_index('movieId')\ntitles = movies.to_dict()['title']"},{"cell_type":"markdown","metadata":{},"source":["Let's recommend some movies for some users."]},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":"def recommend(user, train_set, predicitons, titles, topn = 10):\n    print(f\"For user {user}, the top {topn} movies we recommend:\")\n    prediction = predictions[user]\n    already_items = train_set[user]['movieId'].tolist()\n    i = 0\n    result = []\n    prediction = sorted(prediction, key = lambda x:x[1][1], reverse = True)\n    for movie, score in prediction:\n        if movie not in already_items:\n            result.append((movie, titles[movie], score[1]))\n            i += 1\n        if i == topn:\n            break\n    result = pd.DataFrame(result)\n    result.columns = ['movieId', 'title', 'score']\n    print(result)\n    return result\n"},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":"#recomd = recommend(3, train_set, predictions, titles)\nfor user in [1,2]:\n    recommend(user, train_set, predictions, titles, 10)\n    print('_____________________________________________________________')"}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}